// ==========================================================
// üî± RAWN PRO ‚Äì API Chat Route
// Intelig√™ncia de Conversa com OpenAI + System Prompt
// Vers√£o 2025 ‚Äì Compat√≠vel com Next.js 15 e Streaming
// ==========================================================

import OpenAI from "openai";
import { SYSTEM_PROMPT } from "../../lib/system-prompt"; // ‚úÖ Caminho corrigido (relativo)

// ==========================================================
// üß† Configura√ß√£o do Cliente OpenAI
// ==========================================================
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ==========================================================
// üöÄ Rota Principal ‚Äì Comunica√ß√£o com o Modelo GPT
// ==========================================================
export async function POST(req) {
  try {
    // Recebe mensagens do frontend (Chat)
    const { messages } = await req.json();

    // Requisi√ß√£o ao modelo com System Prompt do RAWN PRO
    const completion = await client.chat.completions.create({
      model: "gpt-4o-mini", // r√°pido, coerente e otimizado
      temperature: 0.8,
      max_tokens: 800,
      stream: true,
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT,
        },
        ...messages,
      ],
    });

    // ========================================================
    // üì° STREAMING ‚Äì Envia o texto conforme o modelo responde
    // ========================================================
    const encoder = new TextEncoder();

    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of completion) {
            const content = chunk.choices?.[0]?.delta?.content;
            if (content) controller.enqueue(encoder.encode(content));
          }
        } catch (err) {
          console.error("Erro no streaming:", err);
          controller.enqueue(encoder.encode("‚ö†Ô∏è Erro ao gerar resposta."));
        } finally {
          controller.close();
        }
      },
    });

    // Retorna o stream da resposta para o frontend
    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
      },
    });
  } catch (error) {
    console.error("‚ùå Erro interno na rota /api/chat:", error);
    return new Response("Erro interno no RAWN PRO", { status: 500 });
  }
}
